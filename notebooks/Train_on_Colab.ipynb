{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPmYRChjDWO23xee8LgmAC4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markwilkening21/tal-teasers/blob/main/notebooks/Train_on_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/markwilkening21/tal-teasers/blob/main/notebooks/Train_on_Colab.ipynb)\n",
        "  "
      ],
      "metadata": {
        "id": "jan714xAh4jS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "import os, torch\n",
        "os.environ[\"USE_TF\"]=\"0\"; os.environ[\"USE_FLAX\"]=\"0\"\n",
        "os.environ[\"TRANSFORMERS_NO_TF\"]=\"1\"; os.environ[\"TRANSFORMERS_NO_FLAX\"]=\"1\"\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqBcvcP5iCvV",
        "outputId": "8dc901ea-2b87-49dd-ca3a-6118ce2e54e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 28 21:23:58 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8             11W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REPO = \"markwilkening21/tal-teasers\"\n",
        "WORKDIR = \"/content/talteasers\"\n",
        "\n",
        "import os\n",
        "if not os.path.exists(WORKDIR):\n",
        "    !git clone https://github.com/{REPO}.git {WORKDIR}\n",
        "else:\n",
        "    %cd {WORKDIR}\n",
        "    !git pull\n",
        "%cd {WORKDIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guJXeL-JiJaK",
        "outputId": "aa17195d-9dea-444a-cba8-8446ae872fee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/talteasers\n",
            "Already up to date.\n",
            "/content/talteasers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U \"transformers>=4.55\" datasets evaluate rouge-score bert-score tqdm matplotlib"
      ],
      "metadata": {
        "id": "q6xYhCpSjjRO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U pip\n",
        "!pip -q install --upgrade transformers datasets evaluate rouge-score bert-score tqdm matplotlib"
      ],
      "metadata": {
        "id": "Dwzd-NmUiMAV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data"
      ],
      "metadata": {
        "id": "bR2PezaKiOYU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m src.train \\\n",
        "  --model-checkpoint t5-small \\\n",
        "  --epochs 1 \\\n",
        "  --train-batch-size 2 \\\n",
        "  --eval-batch-size 2 \\\n",
        "  --grad-accum-steps 4 \\\n",
        "  --eval-strategy no \\\n",
        "  --fp16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1XLtlkriPZm",
        "outputId": "c244e914-147c-48d8-dce7-db009bb19a12"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 630 rows from merged dataset at /content/talteasers/data/episode_summaries_with_transcripts.csv\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['episode_id', 'url', 'title', 'input_text', 'summary'],\n",
            "        num_rows: 504\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['episode_id', 'url', 'title', 'input_text', 'summary'],\n",
            "        num_rows: 126\n",
            "    })\n",
            "})\n",
            "config.json: 100% 1.21k/1.21k [00:00<00:00, 7.67MB/s]\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 3.60MB/s]\n",
            "tokenizer.json: 100% 1.39M/1.39M [00:00<00:00, 4.73MB/s]\n",
            "Tokenizing dataset:   0% 0/504 [00:00<?, ? examples/s]/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4006: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Tokenizing dataset: 100% 504/504 [00:16<00:00, 30.41 examples/s]\n",
            "Tokenizing dataset: 100% 126/126 [00:04<00:00, 28.80 examples/s]\n",
            "config.json: 100% 1.21k/1.21k [00:00<00:00, 11.0MB/s]\n",
            "model.safetensors: 100% 242M/242M [00:02<00:00, 115MB/s]\n",
            "generation_config.json: 100% 147/147 [00:00<00:00, 1.12MB/s]\n",
            "Downloading builder script: 6.27kB [00:00, 17.3MB/s]\n",
            "{'loss': 3.8777, 'grad_norm': 2.412166118621826, 'learning_rate': 1.25e-05, 'epoch': 0.79}\n",
            "{'train_runtime': 40.8161, 'train_samples_per_second': 12.348, 'train_steps_per_second': 1.544, 'train_loss': 3.7995934259323847, 'epoch': 1.0}\n",
            "100% 63/63 [00:40<00:00,  1.54it/s]\n",
            "Saved fine-tuned model & tokenizer to: /content/talteasers/models/fine_tuned_summary_model_base\n"
          ]
        }
      ]
    }
  ]
}